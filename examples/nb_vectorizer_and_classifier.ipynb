{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `SVM` with `NB` features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements shows how to use the NB-SVM classifier from [this paper](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) that has become a classic (and competitive) baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## toy dataset (binary)\n",
    "\n",
    "Working example borrowed from [Stanford IR online text](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html)\n",
    "\n",
    "| docID | text                                | label     |\n",
    "|-------|-------------------------------------|-----------|\n",
    "| 1     | chinese beijing chinese             | CHINA     |\n",
    "| 2     | chinese chinese shanghai            | CHINA     |\n",
    "| 3     | chinese macao                       | CHINA     |\n",
    "| 4     | tokyo japan chinese                 | NOT_CHINA |\n",
    "| 5     | chinese chinese chinese tokyo japan | ???       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_one = \"chinese beijing chinese\"\n",
    "label_one = 1\n",
    "\n",
    "doc_two = \"chinese chinese shanghai\"\n",
    "label_two = 1\n",
    "\n",
    "doc_three = \"chinese macao\"\n",
    "label_three = 1\n",
    "\n",
    "doc_four = \"tokyo japan chinese\"\n",
    "label_four = 0\n",
    "\n",
    "all_docs = [doc_one, doc_two, doc_three, doc_four]\n",
    "all_labels = [label_one, label_two, label_three, label_four]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import inspect\n",
    "import os\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(0, os.path.join(parentdir, 'nb_transformer'))\n",
    "from nb_transformer import NaiveBayesTransformer\n",
    "from nb_enhanced_classifier import NaiveBayesEnhancedClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traditional `bernoulli` `vectorizer`\n",
    "\n",
    "First let's `vectorize` the documents in the training set using `CountVectorizer()`. <br>\n",
    "The paper found binary features to be more effective than raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_bernoulli = CountVectorizer(\n",
    "    binary=True\n",
    ")\n",
    "X_bernoulli = vectorizer_bernoulli.fit_transform(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beijing': 0, 'chinese': 1, 'japan': 2, 'macao': 3, 'shanghai': 4, 'tokyo': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_bernoulli.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bernoulli.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `NaiveBayesTransformer`\n",
    "\n",
    "This is a custom `transformer` that will use the Naive Bayes conditional probabilities as feature values.  See [the paper](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf) for details.\n",
    "\n",
    "The key thing to recognize is that this method is built off of the assumption of a `binary` (only two labels) problem.  It can be expanded to `multiclass` utilizing the `one-v-all` approach, but this also requires a **different** transformation for **each** label, thus the inclusion of `label_of_interest` as an argument to the `NaiveBayesTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_transformer = NaiveBayesTransformer(all_labels, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_features = vectorizer_bernoulli.fit_transform(all_docs)\n",
    "original_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformed feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40546511,  0.40546511,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.40546511,  0.        ,  0.        ,  0.40546511,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.40546511,  0.        ,  0.40546511,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.        ,  0.40546511, -0.98082925,  0.        ,  0.        ,\n",
       "        -0.98082925]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_transformed = nb_transformer.transform(original_features)\n",
    "nb_transformed.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our features, let's train a classifier to predict `1` v. `0`. \n",
    "The paper found an `SVM` with `squared loss` and `l2` penalizing to be most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_clf = LinearSVC(            \n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    random_state = 1,         # to ensure reproducible results\n",
    "    class_weight='balanced',\n",
    "    dual=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build an instance of `NaiveBayesEnchancedClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': 'balanced',\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'loss': 'squared_hinge',\n",
       " 'max_iter': 1000,\n",
       " 'multi_class': 'ovr',\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 1,\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_example_clf = NaiveBayesEnhancedClassifier(\n",
    "    list_of_possible_classes=[0,1],\n",
    "    clf=svm_clf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on our dataset by feeding the *original* vectorized features into `.fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_example_clf.fit(original_features, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baked into `.fit()` are the following steps:\n",
    " 1. `transform` the features using the `NaiveBayesTransformer`\n",
    " 2. Apply an interpolation of weights to the `.coef_` of the `classifier` using the formula below: \n",
    "  - $w' = (1 - \\beta)\\bar{w} + \\beta w$ where $\\bar{w}$ is the mean magnitude of all the weights\n",
    "  \n",
    "Below are a few cells showing the calculations that are done in `NaiveBayesTransformer._interpolate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3158278 ,  0.32634704,  0.45491727,  0.3158278 ,  0.3158278 ,\n",
       "         0.45491727]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interpolation_factor = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36394416,  0.36394416,  0.36394416,  0.36394416,  0.36394416,\n",
       "         0.36394416]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_magnitude = np.sum(svm_clf.coef_)/svm_clf.coef_.shape[1]\n",
    "mean_magnitude_vector = np.full(svm_clf.coef_.shape, mean_magnitude)\n",
    "mean_magnitude_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35191507,  0.35454488,  0.38668744,  0.35191507,  0.35191507,\n",
       "         0.38668744]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.coef_ = (1 - interpolation_factor) * mean_magnitude_vector + \\\n",
    "                                interpolation_factor * svm_clf.coef_\n",
    "svm_clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict on a new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_doc = \"chinese chinese chinese tokyo japan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first must `vectorize` the test item into the original feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features_original = vectorizer_bernoulli.transform([test_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use `NaiveBayesEnhancedClassifier.predict()` to (1) apply the `NB-transformation` and make our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_example_clf.predict(test_features_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the \"confidence\" of this prediction using `NaiveBayesEnhancedClassifier.decision_function_predict_proba(test_features_original)` which will use `.decision_function()` or `.predict_proba()` of the original `classifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08810003])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_example_clf.decision_function_predict_proba(test_features_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicts the test document to be in the `not China` class but not with much confidence.  \n",
    "\n",
    "Note: This is opposite the prediction made in the Stanford IR worked example because they use `multinomial NB` and the presence of \"China\" three times outweighed the presence of the other words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `multiclass` test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained above, this transformation is built for `binary` classification.  The `multiclass` version requires the application of `one-v-all` to a traditional `SVM` classifier.  This is all done automatically within the `NaiveBayesEnhancedClassifier` `class`.  An example is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obvious_docs = [\n",
    "    \"cat\",\n",
    "    \"cat\",\n",
    "    \"cat\",\n",
    "    \"pencil\",\n",
    "    \"pencil\",\n",
    "    \"pencil\",\n",
    "    \"car\",\n",
    "    \"car\",\n",
    "    \"car\",\n",
    "]\n",
    "\n",
    "obvious_labels = [\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2\n",
    "]\n",
    "\n",
    "test_docs = [\n",
    "    \"cat\",\n",
    "    \"pen\",\n",
    "    \"pencil\",\n",
    "    \"car\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### traditional `bernoulli` `vectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiclass_bernoulli_vectorizer = CountVectorizer(\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "multiclass_original_features = multiclass_bernoulli_vectorizer.fit_transform(obvious_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_original_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiclass_example_clf = NaiveBayesEnhancedClassifier(\n",
    "    [0,1,2]      # we'll use the default settings for `clf`\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multiclass_example_clf.fit(\n",
    "    multiclass_bernoulli_vectorizer.fit_transform(obvious_docs),   # vectorize the original documents\n",
    "    obvious_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's project the test documents into the same feature space as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_test_features = multiclass_bernoulli_vectorizer.transform(test_docs)\n",
    "multiclass_test_features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's get predictions for each test document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_example_clf.predict(multiclass_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, the classifier is generating predictions for how likely the data point is in that class.  We can see these values by calling `NaiveBayesEnhancedClassifier.decision_function_predict_proba()`.\n",
    "\n",
    "Below, each row is a classifier trained for a different label.  The values in the vector represent the margin of each data point from the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.48603643 -0.46415139 -0.98429487 -1.06914084]\n",
      "1 [-0.98429487 -0.46415139  0.48603643 -1.06914084]\n",
      "2 [-0.98429487 -0.46415139 -0.98429487  0.64103138]\n"
     ]
    }
   ],
   "source": [
    "for i, row in zip([0,1,2], multiclass_example_clf.decision_function_predict_proba(multiclass_test_features)):\n",
    "    print(i, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then select the \"most confident\" classifier for each data point, where \"most confident\" is the one with the largest *positive* (or, if they're all *negative*, the *smallest*) margin.  In this case, each column is a data point, so we take the `argmax` of each column.\n",
    "\n",
    "Note: Since the second data point (\"pen\") was never seen in the training vocabulary, the classifiers all generate the same prediction, none of which are positive (implying a low level of confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on `20Newsgroups`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we attempt to recreate the `binary` classification problems in the experiments of the [original paper](https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf).  Whenever provided, we use the same hyperparameters.\n",
    "\n",
    "We also compare different classifiers and the use of (1) no transformer or (2) `TfidfVectorizer()`.\n",
    "\n",
    "Note: It's likely that the data coming from `sklearn` for `20Newsgroups` is *not* exactly the same as the data used by the authors.  But the results are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `alt.atheism` v. `talk.religion.misc` (`AthR`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'alt.atheism', 'talk.religion.misc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = (\n",
    "    'headers'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'alt.atheism', 1: 'talk.religion.misc'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "\n",
    "idx2class_lookup = dict((i,c) for i,c in enumerate(data_train.target_names))\n",
    "idx2class_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 480)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label distribution\n",
    "num_pos = list(data_train.target).count(1)\n",
    "num_neg = list(data_train.target).count(0)\n",
    "num_pos, num_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_vectorizer_uni = CountVectorizer(\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "newsgroups_vectorizer_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<857x17440 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 136539 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train_features_uni = newsgroups_vectorizer_uni.fit_transform(data_train.data)\n",
    "newsgroups_train_features_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<570x17440 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 86232 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test_features_uni = newsgroups_vectorizer_uni.transform(data_test.data)\n",
    "newsgroups_test_features_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformed - nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    random_state=1,\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_nb_plus_clfs = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    newsgroups_nb_plus_clfs[clf_name] = NaiveBayesEnhancedClassifier(\n",
    "        list(map(lambda x: x[0], idx2class_lookup.items())),\n",
    "        clf,\n",
    "        interpolation_factor=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training svm_from_paper - nb transformed\n",
      "training sgd - nb transformed\n",
      "training ridge - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training perceptron - nb transformed\n",
      "training passive_aggressive - nb transformed\n",
      "training random_forest - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mcapizzi/data/Github/naive-bayes-transformer/nb_transformer/nb_enhanced_classifier.py:137: UserWarning:\n",
      "\n",
      "the classifier you instantiated does not have an attribute `.coef_`interpolation will not occur\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training adaboost - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mcapizzi/data/Github/naive-bayes-transformer/nb_transformer/nb_enhanced_classifier.py:137: UserWarning:\n",
      "\n",
      "the classifier you instantiated does not have an attribute `.coef_`interpolation will not occur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformed - nb\n",
    "for clf_name, clf in newsgroups_nb_plus_clfs.items():\n",
    "    print(\"training {} - nb transformed\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing transformed svm_from_paper\n",
      "testing transformed sgd\n",
      "testing transformed ridge\n",
      "testing transformed perceptron\n",
      "testing transformed passive_aggressive\n",
      "testing transformed random_forest\n",
      "testing transformed adaboost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.83333333333333337),\n",
       "             ('sgd', 0.81403508771929822),\n",
       "             ('ridge', 0.79824561403508776),\n",
       "             ('perceptron', 0.80701754385964908),\n",
       "             ('passive_aggressive', 0.84736842105263155),\n",
       "             ('random_forest', 0.77894736842105261),\n",
       "             ('adaboost', 0.75964912280701757)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_nb_transformed_uni_results = OrderedDict()\n",
    "for clf_name, clf in newsgroups_nb_plus_clfs.items():\n",
    "    print(\"testing transformed {}\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_nb_transformed_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_nb_transformed_uni_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    dual=False,\n",
    "    C=0.1,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"bernoulli_nb\"] = BernoulliNB(\n",
    "    alpha=0.01,\n",
    ")\n",
    "\n",
    "all_classifiers[\"multinomial_nb\"] = MultinomialNB(\n",
    "    alpha=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline svm_from_paper - no transformation\n",
      "training baseline sgd - no transformation\n",
      "training baseline ridge - no transformation\n",
      "training baseline perceptron - no transformation\n",
      "training baseline passive_aggressive - no transformation\n",
      "training baseline random_forest - no transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline adaboost - no transformation\n",
      "training baseline bernoulli_nb - no transformation\n",
      "training baseline multinomial_nb - no transformation\n"
     ]
    }
   ],
   "source": [
    "# no transformation count\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"training baseline {} - no transformation\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing baseline svm_from_paper - no transformation\n",
      "testing baseline sgd - no transformation\n",
      "testing baseline ridge - no transformation\n",
      "testing baseline perceptron - no transformation\n",
      "testing baseline passive_aggressive - no transformation\n",
      "testing baseline random_forest - no transformation\n",
      "testing baseline adaboost - no transformation\n",
      "testing baseline bernoulli_nb - no transformation\n",
      "testing baseline multinomial_nb - no transformation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.77719298245614032),\n",
       "             ('sgd', 0.756140350877193),\n",
       "             ('ridge', 0.77017543859649118),\n",
       "             ('perceptron', 0.76666666666666672),\n",
       "             ('passive_aggressive', 0.77017543859649118),\n",
       "             ('random_forest', 0.77894736842105261),\n",
       "             ('adaboost', 0.75964912280701757),\n",
       "             ('bernoulli_nb', 0.83157894736842108),\n",
       "             ('multinomial_nb', 0.83684210526315794)])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_no_transformation_uni_results = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"testing baseline {} - no transformation\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_no_transformation_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_no_transformation_uni_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_train_features_uni = newsgroups_vectorizer_tfidf.fit_transform(data_train.data)\n",
    "newsgroups_test_features_uni = newsgroups_vectorizer_tfidf.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    C=0.1,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"bernoulli_nb\"] = BernoulliNB(\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "all_classifiers[\"multinomial_nb\"] = MultinomialNB(\n",
    "    alpha=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline svm_from_paper - tfidf transformation\n",
      "training baseline sgd - tfidf transformation\n",
      "training baseline ridge - tfidf transformation\n",
      "training baseline perceptron - tfidf transformation\n",
      "training baseline passive_aggressive - tfidf transformation\n",
      "training baseline random_forest - tfidf transformation\n",
      "training baseline adaboost - tfidf transformation\n",
      "training baseline bernoulli_nb - tfidf transformation\n",
      "training baseline multinomial_nb - tfidf transformation\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"training baseline {} - tfidf transformation\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing baseline svm_from_paper - no transformation\n",
      "testing baseline sgd - no transformation\n",
      "testing baseline ridge - no transformation\n",
      "testing baseline perceptron - no transformation\n",
      "testing baseline passive_aggressive - no transformation\n",
      "testing baseline random_forest - no transformation\n",
      "testing baseline adaboost - no transformation\n",
      "testing baseline bernoulli_nb - no transformation\n",
      "testing baseline multinomial_nb - no transformation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.79649122807017547),\n",
       "             ('sgd', 0.81228070175438594),\n",
       "             ('ridge', 0.81403508771929822),\n",
       "             ('perceptron', 0.7929824561403509),\n",
       "             ('passive_aggressive', 0.82105263157894737),\n",
       "             ('random_forest', 0.75438596491228072),\n",
       "             ('adaboost', 0.74210526315789471),\n",
       "             ('bernoulli_nb', 0.83157894736842108),\n",
       "             ('multinomial_nb', 0.83859649122807023)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_tfidf_transformed_uni_results = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"testing baseline {} - no transformation\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_tfidf_transformed_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_tfidf_transformed_uni_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "no_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.7771929824561403,
          0.756140350877193,
          0.7701754385964912,
          0.7666666666666667,
          0.7701754385964912,
          0.7789473684210526,
          0.7596491228070176,
          0.8315789473684211,
          0.8368421052631579
         ]
        },
        {
         "name": "tfidf_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.7964912280701755,
          0.8122807017543859,
          0.8140350877192982,
          0.7929824561403509,
          0.8210526315789474,
          0.7543859649122807,
          0.7421052631578947,
          0.8315789473684211,
          0.8385964912280702
         ]
        },
        {
         "name": "nb_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.8333333333333334,
          0.8140350877192982,
          0.7982456140350878,
          0.8070175438596491,
          0.8473684210526315,
          0.7789473684210526,
          0.7596491228070176,
          0,
          0
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "title": "Transformation comparison: AthR (2.9)",
        "yaxis": {
         "range": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"bf44906f-34b0-4de2-b730-dacb5f077298\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bf44906f-34b0-4de2-b730-dacb5f077298\", [{\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.7771929824561403, 0.756140350877193, 0.7701754385964912, 0.7666666666666667, 0.7701754385964912, 0.7789473684210526, 0.7596491228070176, 0.8315789473684211, 0.8368421052631579], \"name\": \"no_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.7964912280701755, 0.8122807017543859, 0.8140350877192982, 0.7929824561403509, 0.8210526315789474, 0.7543859649122807, 0.7421052631578947, 0.8315789473684211, 0.8385964912280702], \"name\": \"tfidf_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8333333333333334, 0.8140350877192982, 0.7982456140350878, 0.8070175438596491, 0.8473684210526315, 0.7789473684210526, 0.7596491228070176, 0.0, 0.0], \"name\": \"nb_transform\"}], {\"barmode\": \"group\", \"title\": \"Transformation comparison: AthR (2.9)\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"bf44906f-34b0-4de2-b730-dacb5f077298\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"bf44906f-34b0-4de2-b730-dacb5f077298\", [{\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.7771929824561403, 0.756140350877193, 0.7701754385964912, 0.7666666666666667, 0.7701754385964912, 0.7789473684210526, 0.7596491228070176, 0.8315789473684211, 0.8368421052631579], \"name\": \"no_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.7964912280701755, 0.8122807017543859, 0.8140350877192982, 0.7929824561403509, 0.8210526315789474, 0.7543859649122807, 0.7421052631578947, 0.8315789473684211, 0.8385964912280702], \"name\": \"tfidf_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8333333333333334, 0.8140350877192982, 0.7982456140350878, 0.8070175438596491, 0.8473684210526315, 0.7789473684210526, 0.7596491228070176, 0.0, 0.0], \"name\": \"nb_transform\"}], {\"barmode\": \"group\", \"title\": \"Transformation comparison: AthR (2.9)\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = [\n",
    "    (\"no_transform\", newsgroups_no_transformation_uni_results),\n",
    "    (\"tfidf_transform\", newsgroups_tfidf_transformed_uni_results), \n",
    "    (\"nb_transform\", newsgroups_nb_transformed_uni_results)\n",
    "]\n",
    "\n",
    "clfs = list(all_classifiers.keys())\n",
    "\n",
    "traces = OrderedDict()\n",
    "for i in range(len(groups)):\n",
    "    transformation = groups[i][1]\n",
    "    transformation_name = groups[i][0]\n",
    "    scores = []\n",
    "    for label in clfs:\n",
    "        try:\n",
    "            score = transformation[label]\n",
    "        except:\n",
    "            score = 0.0\n",
    "        scores.append(score)\n",
    "    traces[\"trace_{}\".format(transformation_name)] = go.Bar(\n",
    "        x=clfs,\n",
    "        y=scores,\n",
    "        name=transformation_name,\n",
    "    )\n",
    "\n",
    "data_ = [v for k, v in traces.items()]\n",
    "layout_ = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Transformation comparison: AthR (2.9)',\n",
    "    yaxis=dict(\n",
    "        range=[0, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_ = go.Figure(data=data_, layout=layout_)\n",
    "iplot(fig_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `comp.graphics` v. `comp.windows.x` (`XGraph`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'comp.graphics', 'comp.windows.x',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'comp.graphics', 1: 'comp.windows.x'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "\n",
    "idx2class_lookup = dict((i,c) for i,c in enumerate(data_train.target_names))\n",
    "idx2class_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(593, 584)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label distribution\n",
    "num_pos = list(data_train.target).count(1)\n",
    "num_neg = list(data_train.target).count(0)\n",
    "num_pos, num_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_vectorizer_uni = CountVectorizer(\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "newsgroups_vectorizer_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1177x21163 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 136868 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train_features_uni = newsgroups_vectorizer_uni.fit_transform(data_train.data)\n",
    "newsgroups_train_features_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<784x21163 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 89865 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test_features_uni = newsgroups_vectorizer_uni.transform(data_test.data)\n",
    "newsgroups_test_features_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformed - nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    random_state=1,\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_nb_plus_clfs = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    newsgroups_nb_plus_clfs[clf_name] = NaiveBayesEnhancedClassifier(\n",
    "        list(map(lambda x: x[0], idx2class_lookup.items())),\n",
    "        clf,\n",
    "        interpolation_factor=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training svm_from_paper - nb transformed\n",
      "training sgd - nb transformed\n",
      "training ridge - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training perceptron - nb transformed\n",
      "training passive_aggressive - nb transformed\n",
      "training random_forest - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mcapizzi/data/Github/naive-bayes-transformer/nb_transformer/nb_enhanced_classifier.py:137: UserWarning:\n",
      "\n",
      "the classifier you instantiated does not have an attribute `.coef_`interpolation will not occur\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training adaboost - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mcapizzi/data/Github/naive-bayes-transformer/nb_transformer/nb_enhanced_classifier.py:137: UserWarning:\n",
      "\n",
      "the classifier you instantiated does not have an attribute `.coef_`interpolation will not occur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformed - nb\n",
    "for clf_name, clf in newsgroups_nb_plus_clfs.items():\n",
    "    print(\"training {} - nb transformed\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing transformed svm_from_paper\n",
      "testing transformed sgd\n",
      "testing transformed ridge\n",
      "testing transformed perceptron\n",
      "testing transformed passive_aggressive\n",
      "testing transformed random_forest\n",
      "testing transformed adaboost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.83290816326530615),\n",
       "             ('sgd', 0.84183673469387754),\n",
       "             ('ridge', 0.83673469387755106),\n",
       "             ('perceptron', 0.8482142857142857),\n",
       "             ('passive_aggressive', 0.84693877551020413),\n",
       "             ('random_forest', 0.80612244897959184),\n",
       "             ('adaboost', 0.81122448979591832)])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_nb_transformed_uni_results = OrderedDict()\n",
    "for clf_name, clf in newsgroups_nb_plus_clfs.items():\n",
    "    print(\"testing transformed {}\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_nb_transformed_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_nb_transformed_uni_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    dual=False,\n",
    "    C=0.1,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"bernoulli_nb\"] = BernoulliNB(\n",
    "    alpha=0.01,\n",
    ")\n",
    "\n",
    "all_classifiers[\"multinomial_nb\"] = MultinomialNB(\n",
    "    alpha=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline svm_from_paper - no transformation\n",
      "training baseline sgd - no transformation\n",
      "training baseline ridge - no transformation\n",
      "training baseline perceptron - no transformation\n",
      "training baseline passive_aggressive - no transformation\n",
      "training baseline random_forest - no transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline adaboost - no transformation\n",
      "training baseline bernoulli_nb - no transformation\n",
      "training baseline multinomial_nb - no transformation\n"
     ]
    }
   ],
   "source": [
    "# no transformation count\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"training baseline {} - no transformation\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing baseline svm_from_paper - no transformation\n",
      "testing baseline sgd - no transformation\n",
      "testing baseline ridge - no transformation\n",
      "testing baseline perceptron - no transformation\n",
      "testing baseline passive_aggressive - no transformation\n",
      "testing baseline random_forest - no transformation\n",
      "testing baseline adaboost - no transformation\n",
      "testing baseline bernoulli_nb - no transformation\n",
      "testing baseline multinomial_nb - no transformation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.82397959183673475),\n",
       "             ('sgd', 0.8482142857142857),\n",
       "             ('ridge', 0.83418367346938771),\n",
       "             ('perceptron', 0.83290816326530615),\n",
       "             ('passive_aggressive', 0.82908163265306123),\n",
       "             ('random_forest', 0.81377551020408168),\n",
       "             ('adaboost', 0.81122448979591832),\n",
       "             ('bernoulli_nb', 0.81760204081632648),\n",
       "             ('multinomial_nb', 0.86352040816326525)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_no_transformation_uni_results = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"testing baseline {} - no transformation\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_no_transformation_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_no_transformation_uni_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_train_features_uni = newsgroups_vectorizer_tfidf.fit_transform(data_train.data)\n",
    "newsgroups_test_features_uni = newsgroups_vectorizer_tfidf.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    C=0.1,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"bernoulli_nb\"] = BernoulliNB(\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "all_classifiers[\"multinomial_nb\"] = MultinomialNB(\n",
    "    alpha=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline svm_from_paper - tfidf transformation\n",
      "training baseline sgd - tfidf transformation\n",
      "training baseline ridge - tfidf transformation\n",
      "training baseline perceptron - tfidf transformation\n",
      "training baseline passive_aggressive - tfidf transformation\n",
      "training baseline random_forest - tfidf transformation\n",
      "training baseline adaboost - tfidf transformation\n",
      "training baseline bernoulli_nb - tfidf transformation\n",
      "training baseline multinomial_nb - tfidf transformation\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"training baseline {} - tfidf transformation\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing baseline svm_from_paper - no transformation\n",
      "testing baseline sgd - no transformation\n",
      "testing baseline ridge - no transformation\n",
      "testing baseline perceptron - no transformation\n",
      "testing baseline passive_aggressive - no transformation\n",
      "testing baseline random_forest - no transformation\n",
      "testing baseline adaboost - no transformation\n",
      "testing baseline bernoulli_nb - no transformation\n",
      "testing baseline multinomial_nb - no transformation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.8482142857142857),\n",
       "             ('sgd', 0.8571428571428571),\n",
       "             ('ridge', 0.85459183673469385),\n",
       "             ('perceptron', 0.84311224489795922),\n",
       "             ('passive_aggressive', 0.85459183673469385),\n",
       "             ('random_forest', 0.80867346938775508),\n",
       "             ('adaboost', 0.78061224489795922),\n",
       "             ('bernoulli_nb', 0.81760204081632648),\n",
       "             ('multinomial_nb', 0.86734693877551017)])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_tfidf_transformed_uni_results = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"testing baseline {} - no transformation\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_tfidf_transformed_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_tfidf_transformed_uni_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "no_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.8239795918367347,
          0.8482142857142857,
          0.8341836734693877,
          0.8329081632653061,
          0.8290816326530612,
          0.8137755102040817,
          0.8112244897959183,
          0.8176020408163265,
          0.8635204081632653
         ]
        },
        {
         "name": "tfidf_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.8482142857142857,
          0.8571428571428571,
          0.8545918367346939,
          0.8431122448979592,
          0.8545918367346939,
          0.8086734693877551,
          0.7806122448979592,
          0.8176020408163265,
          0.8673469387755102
         ]
        },
        {
         "name": "nb_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.8329081632653061,
          0.8418367346938775,
          0.8367346938775511,
          0.8482142857142857,
          0.8469387755102041,
          0.8061224489795918,
          0.8112244897959183,
          0,
          0
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "title": "Transformation comparison: XGraph (1.8)",
        "yaxis": {
         "range": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"d6d5e1d2-9f49-4472-837c-082e29788d2c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d6d5e1d2-9f49-4472-837c-082e29788d2c\", [{\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8239795918367347, 0.8482142857142857, 0.8341836734693877, 0.8329081632653061, 0.8290816326530612, 0.8137755102040817, 0.8112244897959183, 0.8176020408163265, 0.8635204081632653], \"name\": \"no_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8482142857142857, 0.8571428571428571, 0.8545918367346939, 0.8431122448979592, 0.8545918367346939, 0.8086734693877551, 0.7806122448979592, 0.8176020408163265, 0.8673469387755102], \"name\": \"tfidf_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8329081632653061, 0.8418367346938775, 0.8367346938775511, 0.8482142857142857, 0.8469387755102041, 0.8061224489795918, 0.8112244897959183, 0.0, 0.0], \"name\": \"nb_transform\"}], {\"barmode\": \"group\", \"title\": \"Transformation comparison: XGraph (1.8)\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"d6d5e1d2-9f49-4472-837c-082e29788d2c\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d6d5e1d2-9f49-4472-837c-082e29788d2c\", [{\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8239795918367347, 0.8482142857142857, 0.8341836734693877, 0.8329081632653061, 0.8290816326530612, 0.8137755102040817, 0.8112244897959183, 0.8176020408163265, 0.8635204081632653], \"name\": \"no_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8482142857142857, 0.8571428571428571, 0.8545918367346939, 0.8431122448979592, 0.8545918367346939, 0.8086734693877551, 0.7806122448979592, 0.8176020408163265, 0.8673469387755102], \"name\": \"tfidf_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.8329081632653061, 0.8418367346938775, 0.8367346938775511, 0.8482142857142857, 0.8469387755102041, 0.8061224489795918, 0.8112244897959183, 0.0, 0.0], \"name\": \"nb_transform\"}], {\"barmode\": \"group\", \"title\": \"Transformation comparison: XGraph (1.8)\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = [\n",
    "    (\"no_transform\", newsgroups_no_transformation_uni_results),\n",
    "    (\"tfidf_transform\", newsgroups_tfidf_transformed_uni_results), \n",
    "    (\"nb_transform\", newsgroups_nb_transformed_uni_results)\n",
    "]\n",
    "\n",
    "clfs = list(all_classifiers.keys())\n",
    "\n",
    "traces = OrderedDict()\n",
    "for i in range(len(groups)):\n",
    "    transformation = groups[i][1]\n",
    "    transformation_name = groups[i][0]\n",
    "    scores = []\n",
    "    for label in clfs:\n",
    "        try:\n",
    "            score = transformation[label]\n",
    "        except:\n",
    "            score = 0.0\n",
    "        scores.append(score)\n",
    "    traces[\"trace_{}\".format(transformation_name)] = go.Bar(\n",
    "        x=clfs,\n",
    "        y=scores,\n",
    "        name=transformation_name,\n",
    "    )\n",
    "\n",
    "data_ = [v for k, v in traces.items()]\n",
    "layout_ = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Transformation comparison: XGraph (1.8)',\n",
    "    yaxis=dict(\n",
    "        range=[0, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_ = go.Figure(data=data_, layout=layout_)\n",
    "iplot(fig_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `rec.sport.baseball` v. `sci.crypt` (`BbCrypt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'rec.sport.baseball', 'sci.crypt',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'rec.sport.baseball', 1: 'sci.crypt'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "\n",
    "idx2class_lookup = dict((i,c) for i,c in enumerate(data_train.target_names))\n",
    "idx2class_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595, 597)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get label distribution\n",
    "num_pos = list(data_train.target).count(1)\n",
    "num_neg = list(data_train.target).count(0)\n",
    "num_pos, num_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0033557078469723042"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine intercept (log(N+/N-))\n",
    "intercept = np.log(num_pos/num_neg)\n",
    "intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_vectorizer_uni = CountVectorizer(\n",
    "    binary=True\n",
    ")\n",
    "\n",
    "newsgroups_vectorizer_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1192x21197 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 176313 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train_features_uni = newsgroups_vectorizer_uni.fit_transform(data_train.data)\n",
    "newsgroups_train_features_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<793x21197 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 97031 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test_features_uni = newsgroups_vectorizer_uni.transform(data_test.data)\n",
    "newsgroups_test_features_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformed - nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    random_state=1,\n",
    "    dual=False\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_nb_plus_clfs = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    newsgroups_nb_plus_clfs[clf_name] = NaiveBayesEnhancedClassifier(\n",
    "        list(map(lambda x: x[0], idx2class_lookup.items())),\n",
    "        clf,\n",
    "        interpolation_factor=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training svm_from_paper - nb transformed\n",
      "training sgd - nb transformed\n",
      "training ridge - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training perceptron - nb transformed\n",
      "training passive_aggressive - nb transformed\n",
      "training random_forest - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mcapizzi/data/Github/naive-bayes-transformer/nb_transformer/nb_enhanced_classifier.py:137: UserWarning:\n",
      "\n",
      "the classifier you instantiated does not have an attribute `.coef_`interpolation will not occur\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training adaboost - nb transformed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/mcapizzi/data/Github/naive-bayes-transformer/nb_transformer/nb_enhanced_classifier.py:137: UserWarning:\n",
      "\n",
      "the classifier you instantiated does not have an attribute `.coef_`interpolation will not occur\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformed - nb\n",
    "for clf_name, clf in newsgroups_nb_plus_clfs.items():\n",
    "    print(\"training {} - nb transformed\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing transformed svm_from_paper\n",
      "testing transformed sgd\n",
      "testing transformed ridge\n",
      "testing transformed perceptron\n",
      "testing transformed passive_aggressive\n",
      "testing transformed random_forest\n",
      "testing transformed adaboost\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.96216897856242123),\n",
       "             ('sgd', 0.9709962168978562),\n",
       "             ('ridge', 0.96973518284993698),\n",
       "             ('perceptron', 0.97351828499369486),\n",
       "             ('passive_aggressive', 0.98108448928121061),\n",
       "             ('random_forest', 0.94325346784363173),\n",
       "             ('adaboost', 0.9319041614123581)])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_nb_transformed_uni_results = OrderedDict()\n",
    "for clf_name, clf in newsgroups_nb_plus_clfs.items():\n",
    "    print(\"testing transformed {}\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_nb_transformed_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_nb_transformed_uni_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    dual=False,\n",
    "    C=0.1,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"bernoulli_nb\"] = BernoulliNB(\n",
    "    alpha=0.01,\n",
    ")\n",
    "\n",
    "all_classifiers[\"multinomial_nb\"] = MultinomialNB(\n",
    "    alpha=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline svm_from_paper - no transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline sgd - no transformation\n",
      "training baseline ridge - no transformation\n",
      "training baseline perceptron - no transformation\n",
      "training baseline passive_aggressive - no transformation\n",
      "training baseline random_forest - no transformation\n",
      "training baseline adaboost - no transformation\n",
      "training baseline bernoulli_nb - no transformation\n",
      "training baseline multinomial_nb - no transformation\n"
     ]
    }
   ],
   "source": [
    "# no transformation count\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"training baseline {} - no transformation\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing baseline svm_from_paper - no transformation\n",
      "testing baseline sgd - no transformation\n",
      "testing baseline ridge - no transformation\n",
      "testing baseline perceptron - no transformation\n",
      "testing baseline passive_aggressive - no transformation\n",
      "testing baseline random_forest - no transformation\n",
      "testing baseline adaboost - no transformation\n",
      "testing baseline bernoulli_nb - no transformation\n",
      "testing baseline multinomial_nb - no transformation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.95838587641866335),\n",
       "             ('sgd', 0.95586380832282469),\n",
       "             ('ridge', 0.94703656998738961),\n",
       "             ('perceptron', 0.95208070617906682),\n",
       "             ('passive_aggressive', 0.95964691046658257),\n",
       "             ('random_forest', 0.94955863808322827),\n",
       "             ('adaboost', 0.9319041614123581),\n",
       "             ('bernoulli_nb', 0.94703656998738961),\n",
       "             ('multinomial_nb', 0.98612862547288782)])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_no_transformation_uni_results = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"testing baseline {} - no transformation\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_no_transformation_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_no_transformation_uni_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformation - tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsgroups_train_features_uni = newsgroups_vectorizer_tfidf.fit_transform(data_train.data)\n",
    "newsgroups_test_features_uni = newsgroups_vectorizer_tfidf.transform(data_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n",
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning:\n",
      "\n",
      "n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_classifiers = OrderedDict()\n",
    "\n",
    "all_classifiers[\"svm_from_paper\"] = LinearSVC(\n",
    "    loss='squared_hinge',\n",
    "    penalty='l2',\n",
    "    C=0.1,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"sgd\"] = SGDClassifier(\n",
    "    n_iter=50,\n",
    "    penalty='elasticnet',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"ridge\"] = RidgeClassifier(\n",
    "    tol=1e-2,\n",
    "    solver='lsqr',\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"perceptron\"] = Perceptron(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"passive_aggressive\"] = PassiveAggressiveClassifier(\n",
    "    n_iter=50,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"random_forest\"] = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"adaboost\"] = AdaBoostClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "all_classifiers[\"bernoulli_nb\"] = BernoulliNB(\n",
    "    alpha=0.01\n",
    ")\n",
    "\n",
    "all_classifiers[\"multinomial_nb\"] = MultinomialNB(\n",
    "    alpha=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcapizzi/anaconda3/envs/nb_plus_svm/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:319: UserWarning:\n",
      "\n",
      "In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training baseline svm_from_paper - tfidf transformation\n",
      "training baseline sgd - tfidf transformation\n",
      "training baseline ridge - tfidf transformation\n",
      "training baseline perceptron - tfidf transformation\n",
      "training baseline passive_aggressive - tfidf transformation\n",
      "training baseline random_forest - tfidf transformation\n",
      "training baseline adaboost - tfidf transformation\n",
      "training baseline bernoulli_nb - tfidf transformation\n",
      "training baseline multinomial_nb - tfidf transformation\n"
     ]
    }
   ],
   "source": [
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"training baseline {} - tfidf transformation\".format(clf_name))\n",
    "    clf.fit(newsgroups_train_features_uni, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing baseline svm_from_paper - no transformation\n",
      "testing baseline sgd - no transformation\n",
      "testing baseline ridge - no transformation\n",
      "testing baseline perceptron - no transformation\n",
      "testing baseline passive_aggressive - no transformation\n",
      "testing baseline random_forest - no transformation\n",
      "testing baseline adaboost - no transformation\n",
      "testing baseline bernoulli_nb - no transformation\n",
      "testing baseline multinomial_nb - no transformation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('svm_from_paper', 0.95208070617906682),\n",
       "             ('sgd', 0.96343001261034045),\n",
       "             ('ridge', 0.9709962168978562),\n",
       "             ('perceptron', 0.95586380832282469),\n",
       "             ('passive_aggressive', 0.97477931904161408),\n",
       "             ('random_forest', 0.94955863808322827),\n",
       "             ('adaboost', 0.91298865069356872),\n",
       "             ('bernoulli_nb', 0.94703656998738961),\n",
       "             ('multinomial_nb', 0.97982345523329129)])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_tfidf_transformed_uni_results = OrderedDict()\n",
    "for clf_name, clf in all_classifiers.items():\n",
    "    print(\"testing baseline {} - no transformation\".format(clf_name))\n",
    "    preds = clf.predict(newsgroups_test_features_uni)\n",
    "    newsgroups_tfidf_transformed_uni_results[clf_name] = accuracy_score(data_test.target, preds)\n",
    "newsgroups_tfidf_transformed_uni_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "no_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.9583858764186634,
          0.9558638083228247,
          0.9470365699873896,
          0.9520807061790668,
          0.9596469104665826,
          0.9495586380832283,
          0.9319041614123581,
          0.9470365699873896,
          0.9861286254728878
         ]
        },
        {
         "name": "tfidf_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.9520807061790668,
          0.9634300126103404,
          0.9709962168978562,
          0.9558638083228247,
          0.9747793190416141,
          0.9495586380832283,
          0.9129886506935687,
          0.9470365699873896,
          0.9798234552332913
         ]
        },
        {
         "name": "nb_transform",
         "type": "bar",
         "x": [
          "svm_from_paper",
          "sgd",
          "ridge",
          "perceptron",
          "passive_aggressive",
          "random_forest",
          "adaboost",
          "bernoulli_nb",
          "multinomial_nb"
         ],
         "y": [
          0.9621689785624212,
          0.9709962168978562,
          0.969735182849937,
          0.9735182849936949,
          0.9810844892812106,
          0.9432534678436317,
          0.9319041614123581,
          0,
          0
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "title": "Transformation comparison: BbCrypt (0.5)",
        "yaxis": {
         "range": [
          0,
          1
         ]
        }
       }
      },
      "text/html": [
       "<div id=\"15b7f9e7-976b-4417-9c85-d7cdfa2299ff\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"15b7f9e7-976b-4417-9c85-d7cdfa2299ff\", [{\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.9583858764186634, 0.9558638083228247, 0.9470365699873896, 0.9520807061790668, 0.9596469104665826, 0.9495586380832283, 0.9319041614123581, 0.9470365699873896, 0.9861286254728878], \"name\": \"no_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.9520807061790668, 0.9634300126103404, 0.9709962168978562, 0.9558638083228247, 0.9747793190416141, 0.9495586380832283, 0.9129886506935687, 0.9470365699873896, 0.9798234552332913], \"name\": \"tfidf_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.9621689785624212, 0.9709962168978562, 0.969735182849937, 0.9735182849936949, 0.9810844892812106, 0.9432534678436317, 0.9319041614123581, 0.0, 0.0], \"name\": \"nb_transform\"}], {\"barmode\": \"group\", \"title\": \"Transformation comparison: BbCrypt (0.5)\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"15b7f9e7-976b-4417-9c85-d7cdfa2299ff\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"15b7f9e7-976b-4417-9c85-d7cdfa2299ff\", [{\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.9583858764186634, 0.9558638083228247, 0.9470365699873896, 0.9520807061790668, 0.9596469104665826, 0.9495586380832283, 0.9319041614123581, 0.9470365699873896, 0.9861286254728878], \"name\": \"no_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.9520807061790668, 0.9634300126103404, 0.9709962168978562, 0.9558638083228247, 0.9747793190416141, 0.9495586380832283, 0.9129886506935687, 0.9470365699873896, 0.9798234552332913], \"name\": \"tfidf_transform\"}, {\"type\": \"bar\", \"x\": [\"svm_from_paper\", \"sgd\", \"ridge\", \"perceptron\", \"passive_aggressive\", \"random_forest\", \"adaboost\", \"bernoulli_nb\", \"multinomial_nb\"], \"y\": [0.9621689785624212, 0.9709962168978562, 0.969735182849937, 0.9735182849936949, 0.9810844892812106, 0.9432534678436317, 0.9319041614123581, 0.0, 0.0], \"name\": \"nb_transform\"}], {\"barmode\": \"group\", \"title\": \"Transformation comparison: BbCrypt (0.5)\", \"yaxis\": {\"range\": [0, 1]}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = [\n",
    "    (\"no_transform\", newsgroups_no_transformation_uni_results),\n",
    "    (\"tfidf_transform\", newsgroups_tfidf_transformed_uni_results), \n",
    "    (\"nb_transform\", newsgroups_nb_transformed_uni_results)\n",
    "]\n",
    "\n",
    "clfs = list(all_classifiers.keys())\n",
    "\n",
    "traces = OrderedDict()\n",
    "for i in range(len(groups)):\n",
    "    transformation = groups[i][1]\n",
    "    transformation_name = groups[i][0]\n",
    "    scores = []\n",
    "    for label in clfs:\n",
    "        try:\n",
    "            score = transformation[label]\n",
    "        except:\n",
    "            score = 0.0\n",
    "        scores.append(score)\n",
    "    traces[\"trace_{}\".format(transformation_name)] = go.Bar(\n",
    "        x=clfs,\n",
    "        y=scores,\n",
    "        name=transformation_name,\n",
    "    )\n",
    "\n",
    "data_ = [v for k, v in traces.items()]\n",
    "layout_ = go.Layout(\n",
    "    barmode='group',\n",
    "    title='Transformation comparison: BbCrypt (0.5)',\n",
    "    yaxis=dict(\n",
    "        range=[0, 1]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig_ = go.Figure(data=data_, layout=layout_)\n",
    "iplot(fig_)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
